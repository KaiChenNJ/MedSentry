# config/models_config.yaml
# LLM models configuration

models:
  gpt4:
    api_key: "your_openai_api_key"
    base_url: "https://api.openai.com/v1"
    model_name: "gpt-4"
    max_tokens: 2000

  claude:
    api_key: "your_anthropic_api_key"
    base_url: "https://api.anthropic.com"
    model_name: "claude-3-5-sonnet"
    max_tokens: 2000

  deepseek:
    api_key: "your-key"  # Example key, replace with actual
    base_url: "https://api.deepseek.com"
    model_name: "deepseek-chat"
    temperature: 0.1
    max_tokens: 2000

  llama:
    api_key: "your_llama_api_key"
    base_url: "https://api.llama.com"
    model_name: "llama-70b"
    max_tokens: 2000